% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/guardrail-eval.R
\name{guardrail_metrics}
\alias{guardrail_metrics}
\title{Compute guardrail evaluation metrics}
\usage{
guardrail_metrics(eval_result)
}
\arguments{
\item{eval_result}{A \code{guardrail_eval_result} object.}
}
\value{
A named list with tp, tn, fp, fn, precision, recall, f1, accuracy.
}
\description{
Computes precision, recall, F1, accuracy, and confusion counts from
a guardrail evaluation result.
}
\details{
Convention: blocking is the "positive" class.
\itemize{
\item True positive: expected=FALSE (should block) and pass=FALSE (was blocked)
\item True negative: expected=TRUE (should pass) and pass=TRUE (was passed)
\item False positive: expected=TRUE (should pass) but pass=FALSE (was blocked)
\item False negative: expected=FALSE (should block) but pass=TRUE (was passed)
}
}
\examples{
data <- data.frame(
  input = c("hello", "DROP TABLE users"),
  expected = c(TRUE, FALSE)
)
my_guard <- function(text) !grepl("DROP TABLE", text, fixed = TRUE)
result <- guardrail_eval(my_guard, data)
m <- guardrail_metrics(result)
m$precision
m$recall
}
