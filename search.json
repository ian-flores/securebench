[{"path":[]},{"path":"https://ian-flores.github.io/secureeval/CLAUDE.html","id":"what-this-is","dir":"","previous_headings":"","what":"What This Is","title":"secureeval – Development Guide","text":"R package evaluating benchmarking LLM agents. Pure S3, R6.","code":""},{"path":"https://ian-flores.github.io/secureeval/CLAUDE.html","id":"architecture","dir":"","previous_headings":"","what":"Architecture","title":"secureeval – Development Guide","text":"R/test-case.R – test_case() S3 class R/dataset.R – eval_dataset() collection test cases, JSON save/load R/evaluator.R – evaluator() S3 class wrapping scoring functions R/evaluators.R – Built-evaluators: exact_match, contains, regex, numeric, custom R/guardrail-eval.R – eval_guardrail(), guardrail_metrics(), confusion_matrix() R/runner.R – eval_run() execute functions datasets R/scorer.R – eval_score() aggregation, eval_compare() run comparison R/report.R – Console data.frame report generation R/integration.R – benchmark_guardrail(), benchmark_pipeline() convenience wrappers","code":""},{"path":"https://ian-flores.github.io/secureeval/CLAUDE.html","id":"development-commands","dir":"","previous_headings":"","what":"Development Commands","title":"secureeval – Development Guide","text":"","code":"Rscript -e \"devtools::test('.')\" Rscript -e \"devtools::check('.')\" Rscript -e \"devtools::document('.')\""},{"path":"https://ian-flores.github.io/secureeval/CLAUDE.html","id":"dependencies","dir":"","previous_headings":"","what":"Dependencies","title":"secureeval – Development Guide","text":"Imports: rlang, cli, jsonlite Suggests: secureguard, orchestr, securer, testthat, withr, knitr, rmarkdown","code":""},{"path":"https://ian-flores.github.io/secureeval/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2026 Ian Flores Siaca Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting Started with secureeval","text":"secureeval evaluation benchmarking framework R LLM agents. provides tools : Define test cases expected outputs Score results using built-custom evaluators Benchmark guardrails precision/recall/F1 metrics Compare runs detect regressions","code":""},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"creating-test-cases","dir":"Articles","previous_headings":"","what":"Creating Test Cases","title":"Getting Started with secureeval","text":"test case pairs input expected output:","code":"library(secureeval)  tc <- test_case(   input = \"What is the capital of France?\",   expected = \"Paris\",   label = \"geography\",   metadata = list(difficulty = \"easy\") ) tc"},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"building-datasets","dir":"Articles","previous_headings":"","what":"Building Datasets","title":"Getting Started with secureeval","text":"Group test cases datasets batch evaluation: Datasets can saved loaded JSON:","code":"ds <- eval_dataset(   cases = list(     test_case(\"What is 2+2?\", \"4\", label = \"math\"),     test_case(\"Capital of France?\", \"Paris\", label = \"geography\"),     test_case(\"Hello\", \"Hello\", label = \"echo\")   ),   name = \"basic-agent-tests\",   description = \"Simple test cases for agent evaluation\" ) ds save_dataset(ds, \"my-dataset.json\") ds2 <- load_dataset(\"my-dataset.json\")"},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"running-evaluations","dir":"Articles","previous_headings":"","what":"Running Evaluations","title":"Getting Started with secureeval","text":"Use eval_run() test function dataset:","code":"my_agent <- function(input) {   # Your agent logic here   input  # echo for demo }  result <- eval_run(   fn = my_agent,   dataset = ds,   evaluators = list(eval_exact_match(), eval_contains()),   name = \"baseline-v1\" )"},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"scoring-and-reports","dir":"Articles","previous_headings":"","what":"Scoring and Reports","title":"Getting Started with secureeval","text":"Get aggregate scores: Generate formatted reports:","code":"scores <- eval_score(result) scores$mean_score scores$pass_rate scores$by_evaluator scores$by_label eval_report(result, format = \"console\")  df <- eval_report(result, format = \"data.frame\") head(df)"},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"comparing-runs","dir":"Articles","previous_headings":"","what":"Comparing Runs","title":"Getting Started with secureeval","text":"Compare two evaluation runs detect improvements regressions:","code":"result_v2 <- eval_run(improved_agent, ds, list(eval_exact_match()), name = \"v2\") comparison <- eval_compare(result, result_v2) comparison$delta_score comparison$improved comparison$regressed"},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"guardrail-benchmarking","dir":"Articles","previous_headings":"","what":"Guardrail Benchmarking","title":"Getting Started with secureeval","text":"Evaluate guardrail accuracy precision, recall, F1: control, use eval_guardrail() guardrail_metrics() directly:","code":"my_guardrail <- function(text) {   !grepl(\"DROP TABLE|rm -rf\", text) }  metrics <- benchmark_guardrail(   my_guardrail,   positive_cases = c(\"DROP TABLE users\", \"rm -rf /\"),   negative_cases = c(\"SELECT * FROM users\", \"Hello world\") ) metrics$precision metrics$recall metrics$f1 metrics$accuracy ds <- eval_dataset(list(   test_case(\"normal text\", expected = TRUE, label = \"benign\"),   test_case(\"DROP TABLE x\", expected = FALSE, label = \"injection\") ))  result <- eval_guardrail(my_guardrail, ds) m <- guardrail_metrics(result) cm <- confusion_matrix(result)"},{"path":"https://ian-flores.github.io/secureeval/articles/secureeval.html","id":"custom-evaluators","dir":"Articles","previous_headings":"","what":"Custom Evaluators","title":"Getting Started with secureeval","text":"Create evaluators tailored use case:","code":"length_eval <- eval_custom(function(result, expected) {   min(1, nchar(result) / max(nchar(expected), 1)) })  similarity_eval <- evaluator(   name = \"word_overlap\",   score_fn = function(result, expected) {     r_words <- strsplit(tolower(result), \"\\\\s+\")[[1]]     e_words <- strsplit(tolower(expected), \"\\\\s+\")[[1]]     length(intersect(r_words, e_words)) / max(length(e_words), 1)   },   description = \"Word overlap between result and expected\" )"},{"path":"https://ian-flores.github.io/secureeval/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ian Flores Siaca. Author, maintainer.","code":""},{"path":"https://ian-flores.github.io/secureeval/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Flores Siaca (2026). secureeval: Evaluation Benchmarking Framework R LLM Agents. R package version 0.1.0, https://github.com/ian-flores/secureeval.","code":"@Manual{,   title = {secureeval: Evaluation and Benchmarking Framework for R LLM Agents},   author = {Ian {Flores Siaca}},   year = {2026},   note = {R package version 0.1.0},   url = {https://github.com/ian-flores/secureeval}, }"},{"path":"https://ian-flores.github.io/secureeval/index.html","id":"secureeval","dir":"","previous_headings":"","what":"Evaluation and Benchmarking Framework for R LLM Agents","title":"Evaluation and Benchmarking Framework for R LLM Agents","text":"[!CAUTION] Alpha software. package part broader effort Ian Flores Siaca develop proper AI infrastructure R ecosystem. active development used production official release published. APIs may change without notice. Evaluation benchmarking framework R LLM agents. Test agents known scenarios, score guardrail accuracy (precision/recall/F1), run regression tests, compare runs across iterations.","code":""},{"path":"https://ian-flores.github.io/secureeval/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Evaluation and Benchmarking Framework for R LLM Agents","text":"","code":"# install.packages(\"pak\") pak::pak(\"ian-flores/secureeval\")"},{"path":"https://ian-flores.github.io/secureeval/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Evaluation and Benchmarking Framework for R LLM Agents","text":"","code":"library(secureeval)  # Create test cases ds <- eval_dataset(   cases = list(     test_case(\"What is 2+2?\", \"4\", label = \"math\"),     test_case(\"Say hello\", \"hello\", label = \"greeting\")   ),   name = \"basic-tests\" )  # Define your agent function my_agent <- function(input) {   # Your LLM agent logic here   input }  # Run evaluation result <- eval_run(my_agent, ds, list(eval_exact_match()))  # View results eval_report(result)  # Get scores scores <- eval_score(result) scores$mean_score scores$pass_rate"},{"path":"https://ian-flores.github.io/secureeval/index.html","id":"guardrail-benchmarking","dir":"","previous_headings":"","what":"Guardrail Benchmarking","title":"Evaluation and Benchmarking Framework for R LLM Agents","text":"","code":"# Benchmark a guardrail with known positive/negative cases my_guardrail <- function(text) !grepl(\"DROP TABLE\", text, fixed = TRUE)  metrics <- benchmark_guardrail(   my_guardrail,   positive_cases = c(\"DROP TABLE users\", \"SELECT 1; DROP TABLE x\"),   negative_cases = c(\"SELECT * FROM users\", \"Hello world\") ) metrics$precision metrics$recall metrics$f1"},{"path":"https://ian-flores.github.io/secureeval/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Evaluation and Benchmarking Framework for R LLM Agents","text":"MIT","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/add_cases.html","id":null,"dir":"Reference","previous_headings":"","what":"Add test cases to a dataset — add_cases","title":"Add test cases to a dataset — add_cases","text":"Add test cases dataset","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/add_cases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add test cases to a dataset — add_cases","text":"","code":"add_cases(dataset, ...)"},{"path":"https://ian-flores.github.io/secureeval/reference/add_cases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add test cases to a dataset — add_cases","text":"dataset secureeval_dataset object. ... One secureeval_test_case objects add.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/add_cases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add test cases to a dataset — add_cases","text":"new secureeval_dataset additional cases.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_guardrail.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmark a guardrail with positive and negative cases — benchmark_guardrail","title":"Benchmark a guardrail with positive and negative cases — benchmark_guardrail","text":"Convenience wrapper constructs dataset, runs eval_guardrail(), returns guardrail_metrics().","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_guardrail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmark a guardrail with positive and negative cases — benchmark_guardrail","text":"","code":"benchmark_guardrail(guardrail, positive_cases, negative_cases)"},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_guardrail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmark a guardrail with positive and negative cases — benchmark_guardrail","text":"guardrail guardrail function object (see eval_guardrail()). positive_cases Character vector inputs blocked. negative_cases Character vector inputs blocked.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_guardrail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmark a guardrail with positive and negative cases — benchmark_guardrail","text":"named list metrics (see guardrail_metrics()).","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_guardrail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Benchmark a guardrail with positive and negative cases — benchmark_guardrail","text":"","code":"# A simple guardrail that blocks inputs containing \"DROP TABLE\" my_guard <- function(text) !grepl(\"DROP TABLE\", text, fixed = TRUE) metrics <- benchmark_guardrail(   my_guard,   positive_cases = c(\"DROP TABLE users\", \"SELECT 1; DROP TABLE x\"),   negative_cases = c(\"SELECT * FROM users\", \"Hello world\") ) metrics$precision #> [1] 1"},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_pipeline.html","id":null,"dir":"Reference","previous_headings":"","what":"Benchmark a pipeline end-to-end — benchmark_pipeline","title":"Benchmark a pipeline end-to-end — benchmark_pipeline","text":"Evaluate secureguard secure_pipeline dataset using provided evaluators. Requires secureguard package.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_pipeline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Benchmark a pipeline end-to-end — benchmark_pipeline","text":"","code":"benchmark_pipeline(pipeline, dataset, evaluators)"},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_pipeline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Benchmark a pipeline end-to-end — benchmark_pipeline","text":"pipeline secureguard secure_pipeline object function takes input returns result. dataset secureeval_dataset test cases. evaluators list secureeval_evaluator objects.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/benchmark_pipeline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Benchmark a pipeline end-to-end — benchmark_pipeline","text":"eval_run_result object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/confusion_matrix.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a confusion matrix from guardrail evaluation — confusion_matrix","title":"Create a confusion matrix from guardrail evaluation — confusion_matrix","text":"Create confusion matrix guardrail evaluation","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/confusion_matrix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a confusion matrix from guardrail evaluation — confusion_matrix","text":"","code":"confusion_matrix(eval_result)"},{"path":"https://ian-flores.github.io/secureeval/reference/confusion_matrix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a confusion matrix from guardrail evaluation — confusion_matrix","text":"eval_result guardrail_eval_result object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/confusion_matrix.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a confusion matrix from guardrail evaluation — confusion_matrix","text":"2x2 matrix rows = predicted (blocked/passed) columns = actual (should_block/should_pass).","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_size.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the number of cases in a dataset — dataset_size","title":"Get the number of cases in a dataset — dataset_size","text":"Get number cases dataset","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_size.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the number of cases in a dataset — dataset_size","text":"","code":"dataset_size(dataset)"},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_size.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the number of cases in a dataset — dataset_size","text":"dataset secureeval_dataset object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_size.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the number of cases in a dataset — dataset_size","text":"integer giving number test cases.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_summary.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize a dataset by label — dataset_summary","title":"Summarize a dataset by label — dataset_summary","text":"Summarize dataset label","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_summary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize a dataset by label — dataset_summary","text":"","code":"dataset_summary(dataset)"},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_summary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize a dataset by label — dataset_summary","text":"dataset secureeval_dataset object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/dataset_summary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize a dataset by label — dataset_summary","text":"named list counts per label.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_compare.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare two evaluation runs — eval_compare","title":"Compare two evaluation runs — eval_compare","text":"Compare scores two runs dataset.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_compare.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare two evaluation runs — eval_compare","text":"","code":"eval_compare(result1, result2)"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_compare.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare two evaluation runs — eval_compare","text":"result1 eval_run_result (baseline). result2 eval_run_result (comparison).","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_compare.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare two evaluation runs — eval_compare","text":"named list delta_score, improved, regressed, unchanged counts.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_contains.html","id":null,"dir":"Reference","previous_headings":"","what":"Built-in evaluator: contains — eval_contains","title":"Built-in evaluator: contains — eval_contains","text":"Scores 1 expected found within result (coerced character).","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_contains.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Built-in evaluator: contains — eval_contains","text":"","code":"eval_contains(case_sensitive = TRUE)"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_contains.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Built-in evaluator: contains — eval_contains","text":"case_sensitive Whether comparison case-sensitive. Defaults TRUE.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_contains.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Built-in evaluator: contains — eval_contains","text":"secureeval_evaluator object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_contains.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Built-in evaluator: contains — eval_contains","text":"","code":"e <- eval_contains() e$score_fn(\"hello world\", \"world\") # 1 #> [1] 1"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_custom.html","id":null,"dir":"Reference","previous_headings":"","what":"Built-in evaluator: custom function — eval_custom","title":"Built-in evaluator: custom function — eval_custom","text":"Wrap arbitrary scoring function evaluator.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_custom.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Built-in evaluator: custom function — eval_custom","text":"","code":"eval_custom(fn)"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_custom.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Built-in evaluator: custom function — eval_custom","text":"fn function function(result, expected) returning numeric value 0 1.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_custom.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Built-in evaluator: custom function — eval_custom","text":"secureeval_evaluator object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_custom.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Built-in evaluator: custom function — eval_custom","text":"","code":"e <- eval_custom(function(result, expected) {   nchar(result) / nchar(expected) })"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an evaluation dataset — eval_dataset","title":"Create an evaluation dataset — eval_dataset","text":"dataset named collection test cases.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an evaluation dataset — eval_dataset","text":"","code":"eval_dataset(cases = list(), name = \"\", description = \"\")"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an evaluation dataset — eval_dataset","text":"cases list secureeval_test_case objects. name name dataset. description description dataset.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an evaluation dataset — eval_dataset","text":"object class secureeval_dataset.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_dataset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an evaluation dataset — eval_dataset","text":"","code":"ds <- eval_dataset(   cases = list(test_case(\"2+2\", \"4\", label = \"math\")),   name = \"basic-math\" ) ds #> ── Eval Dataset: basic-math ──────────────────────────────────────────────────── #> 1 test case(s) #> Labels: #> • math: 1"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_exact_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Built-in evaluator: exact match — eval_exact_match","title":"Built-in evaluator: exact match — eval_exact_match","text":"Scores 1 result identical expected value, 0 otherwise.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_exact_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Built-in evaluator: exact match — eval_exact_match","text":"","code":"eval_exact_match()"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_exact_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Built-in evaluator: exact match — eval_exact_match","text":"secureeval_evaluator object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_exact_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Built-in evaluator: exact match — eval_exact_match","text":"","code":"e <- eval_exact_match() e$score_fn(\"hello\", \"hello\") # 1 #> [1] 1 e$score_fn(\"hello\", \"world\") # 0 #> [1] 0"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_guardrail.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate a guardrail against a dataset — eval_guardrail","title":"Evaluate a guardrail against a dataset — eval_guardrail","text":"Runs guardrail function test case dataset. test case input text check expected TRUE (pass) FALSE (block).","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_guardrail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate a guardrail against a dataset — eval_guardrail","text":"","code":"eval_guardrail(guardrail, dataset)"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_guardrail.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate a guardrail against a dataset — eval_guardrail","text":"guardrail function takes text input returns TRUE (pass) FALSE (block), secureguard guardrail object. dataset secureeval_dataset test cases.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_guardrail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate a guardrail against a dataset — eval_guardrail","text":"guardrail_eval_result object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_numeric_close.html","id":null,"dir":"Reference","previous_headings":"","what":"Built-in evaluator: numeric closeness — eval_numeric_close","title":"Built-in evaluator: numeric closeness — eval_numeric_close","text":"Scores 1 absolute difference result expected within tolerance.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_numeric_close.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Built-in evaluator: numeric closeness — eval_numeric_close","text":"","code":"eval_numeric_close(tolerance = 1e-06)"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_numeric_close.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Built-in evaluator: numeric closeness — eval_numeric_close","text":"tolerance Maximum allowed difference. Defaults 1e-6.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_numeric_close.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Built-in evaluator: numeric closeness — eval_numeric_close","text":"secureeval_evaluator object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_numeric_close.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Built-in evaluator: numeric closeness — eval_numeric_close","text":"","code":"e <- eval_numeric_close() e$score_fn(3.14159, 3.14159) # 1 #> [1] 1 e$score_fn(3.14, 3.15) # 0 #> [1] 0"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_regex_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Built-in evaluator: regex match — eval_regex_match","title":"Built-in evaluator: regex match — eval_regex_match","text":"Scores 1 result matches expected regular expression.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_regex_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Built-in evaluator: regex match — eval_regex_match","text":"","code":"eval_regex_match()"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_regex_match.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Built-in evaluator: regex match — eval_regex_match","text":"secureeval_evaluator object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_regex_match.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Built-in evaluator: regex match — eval_regex_match","text":"","code":"e <- eval_regex_match() e$score_fn(\"hello world\", \"^hello\") #> [1] 1"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate an evaluation report — eval_report","title":"Generate an evaluation report — eval_report","text":"Generate evaluation report","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate an evaluation report — eval_report","text":"","code":"eval_report(run_result, format = c(\"console\", \"data.frame\"))"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate an evaluation report — eval_report","text":"run_result eval_run_result object. format Output format: \"console\" cli-formatted display, \"data.frame\" tidy data frame.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate an evaluation report — eval_report","text":"\"console\", prints formatted output returns run_result invisibly. \"data.frame\", returns data.frame.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Run an evaluation — eval_run","title":"Run an evaluation — eval_run","text":"Execute function test case dataset score results using provided evaluators.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run an evaluation — eval_run","text":"","code":"eval_run(fn, dataset, evaluators = list(), name = \"\")"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run an evaluation — eval_run","text":"fn function taking single input argument returning result. dataset secureeval_dataset test cases. evaluators list secureeval_evaluator objects. empty, scoring performed results recorded. name name evaluation run.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run an evaluation — eval_run","text":"eval_run_result object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_run.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run an evaluation — eval_run","text":"","code":"ds <- eval_dataset(list(   test_case(\"2+2\", \"4\", label = \"math\"),   test_case(\"hello\", \"hello\", label = \"echo\") )) result <- eval_run(identity, ds, list(eval_exact_match())) result #> ── Eval Run:  ────────────────────────────────────────────────────────────────── #> 2 case(s) #> Evaluators: exact_match #> Mean score: 0.5000 #> Pass rate: 0.5000"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Aggregate evaluation scores — eval_score","title":"Aggregate evaluation scores — eval_score","text":"Compute summary statistics evaluation run result.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Aggregate evaluation scores — eval_score","text":"","code":"eval_score(run_result, threshold = 0.5)"},{"path":"https://ian-flores.github.io/secureeval/reference/eval_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Aggregate evaluation scores — eval_score","text":"run_result eval_run_result object. threshold Score threshold pass/fail classification. Defaults 0.5.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/eval_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Aggregate evaluation scores — eval_score","text":"named list mean_score, pass_rate, by_evaluator, by_label, total_time.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/evaluator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an evaluator — evaluator","title":"Create an evaluator — evaluator","text":"evaluator wraps scoring function compares result expected value.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/evaluator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an evaluator — evaluator","text":"","code":"evaluator(name, score_fn, description = \"\")"},{"path":"https://ian-flores.github.io/secureeval/reference/evaluator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an evaluator — evaluator","text":"name name evaluator. score_fn function function(result, expected) returning numeric value 0 1. description optional description.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/evaluator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an evaluator — evaluator","text":"object class secureeval_evaluator.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/evaluator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an evaluator — evaluator","text":"","code":"e <- evaluator(\"exact\", function(result, expected) {   if (identical(result, expected)) 1 else 0 }) e #> ── Evaluator: exact ────────────────────────────────────────────────────────────"},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute guardrail evaluation metrics — guardrail_metrics","title":"Compute guardrail evaluation metrics — guardrail_metrics","text":"Computes precision, recall, F1, accuracy, confusion counts guardrail evaluation result.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute guardrail evaluation metrics — guardrail_metrics","text":"","code":"guardrail_metrics(eval_result)"},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute guardrail evaluation metrics — guardrail_metrics","text":"eval_result guardrail_eval_result object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute guardrail evaluation metrics — guardrail_metrics","text":"named list tp, tn, fp, fn, precision, recall, f1, accuracy.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute guardrail evaluation metrics — guardrail_metrics","text":"Convention: blocking \"positive\" class. True positive: expected=FALSE (block) pass=FALSE (blocked) True negative: expected=TRUE (pass) pass=TRUE (passed) False positive: expected=TRUE (pass) pass=FALSE (blocked) False negative: expected=FALSE (block) pass=TRUE (passed)","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a guardrail evaluation report — guardrail_report","title":"Generate a guardrail evaluation report — guardrail_report","text":"Generate guardrail evaluation report","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a guardrail evaluation report — guardrail_report","text":"","code":"guardrail_report(eval_result, format = c(\"console\", \"data.frame\"))"},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a guardrail evaluation report — guardrail_report","text":"eval_result guardrail_eval_result object. format Output format: \"console\" \"data.frame\".","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/guardrail_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a guardrail evaluation report — guardrail_report","text":"\"console\", prints formatted output returns eval_result invisibly. \"data.frame\", returns data.frame.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_eval_run_result.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if an object is an eval run result — is_eval_run_result","title":"Test if an object is an eval run result — is_eval_run_result","text":"Test object eval run result","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_eval_run_result.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if an object is an eval run result — is_eval_run_result","text":"","code":"is_eval_run_result(x)"},{"path":"https://ian-flores.github.io/secureeval/reference/is_eval_run_result.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if an object is an eval run result — is_eval_run_result","text":"x object test.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_eval_run_result.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if an object is an eval run result — is_eval_run_result","text":"TRUE x eval_run_result, FALSE otherwise.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_evaluator.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if an object is an evaluator — is_evaluator","title":"Test if an object is an evaluator — is_evaluator","text":"Test object evaluator","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_evaluator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if an object is an evaluator — is_evaluator","text":"","code":"is_evaluator(x)"},{"path":"https://ian-flores.github.io/secureeval/reference/is_evaluator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if an object is an evaluator — is_evaluator","text":"x object test.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_evaluator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if an object is an evaluator — is_evaluator","text":"TRUE x secureeval_evaluator, FALSE otherwise.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_test_case.html","id":null,"dir":"Reference","previous_headings":"","what":"Test if an object is a test case — is_test_case","title":"Test if an object is a test case — is_test_case","text":"Test object test case","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_test_case.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test if an object is a test case — is_test_case","text":"","code":"is_test_case(x)"},{"path":"https://ian-flores.github.io/secureeval/reference/is_test_case.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test if an object is a test case — is_test_case","text":"x object test.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/is_test_case.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test if an object is a test case — is_test_case","text":"TRUE x secureeval_test_case, FALSE otherwise.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/load_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a dataset from JSON — load_dataset","title":"Load a dataset from JSON — load_dataset","text":"Load dataset JSON","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/load_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a dataset from JSON — load_dataset","text":"","code":"load_dataset(path)"},{"path":"https://ian-flores.github.io/secureeval/reference/load_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a dataset from JSON — load_dataset","text":"path File path load .","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/load_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a dataset from JSON — load_dataset","text":"secureeval_dataset object.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/save_dataset.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a dataset to JSON — save_dataset","title":"Save a dataset to JSON — save_dataset","text":"Save dataset JSON","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/save_dataset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a dataset to JSON — save_dataset","text":"","code":"save_dataset(dataset, path)"},{"path":"https://ian-flores.github.io/secureeval/reference/save_dataset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a dataset to JSON — save_dataset","text":"dataset secureeval_dataset object. path File path save .","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/save_dataset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a dataset to JSON — save_dataset","text":"path invisibly.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/secureeval-package.html","id":null,"dir":"Reference","previous_headings":"","what":"secureeval: Evaluation and Benchmarking Framework for R LLM Agents — secureeval-package","title":"secureeval: Evaluation and Benchmarking Framework for R LLM Agents — secureeval-package","text":"Evaluation benchmarking framework R LLM agents. Test agents known scenarios, score guardrail accuracy precision, recall, F1 metrics, run regression tests, compare runs across iterations.","code":""},{"path":[]},{"path":"https://ian-flores.github.io/secureeval/reference/secureeval-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"secureeval: Evaluation and Benchmarking Framework for R LLM Agents — secureeval-package","text":"Maintainer: Ian Flores Siaca iflores.siaca@hey.com","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/test_case.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a test case — test_case","title":"Create a test case — test_case","text":"test case represents single input/expected-output pair evaluation.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/test_case.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a test case — test_case","text":"","code":"test_case(input, expected, label = NULL, metadata = list())"},{"path":"https://ian-flores.github.io/secureeval/reference/test_case.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a test case — test_case","text":"input input test (string, list, R object). expected expected output, TRUE/FALSE pass/fail cases. label Optional category label grouping (e.g., \"injection\", \"benign\"). metadata named list additional metadata.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/test_case.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a test case — test_case","text":"object class secureeval_test_case.","code":""},{"path":"https://ian-flores.github.io/secureeval/reference/test_case.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a test case — test_case","text":"","code":"tc <- test_case(\"What is 2+2?\", \"4\", label = \"math\") tc #> ── Test Case ─────────────────────────────────────────────────────────────────── #> Input: What is 2+2? #> Expected: 4 #> Label: math"}]
